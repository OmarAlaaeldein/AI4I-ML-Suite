{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MultiLabelBinarizer, MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score, jaccard_score\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import mlsmote\n",
        "from skmultilearn.problem_transform import BinaryRelevance\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import product\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from inspect import signature\n",
        "from tensorflow.estimator import DNNClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('ai4i2020.csv',index_col=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "no_data_entries = data.shape[0]\n",
        "repetition_class_ratio= data[['TWF','HDF','PWF','OSF','RNF']].sum(axis=0)/no_data_entries\n",
        "print(repetition_class_ratio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "non_failure_samples_no= no_data_entries-data[[\"Machine failure\"]].sum(axis=0).values[0]\n",
        "print(non_failure_samples_no)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classifiers = [\n",
        "    XGBClassifier,\n",
        "    LGBMClassifier,\n",
        "    CatBoostClassifier,\n",
        "    RandomForestClassifier,\n",
        "    GradientBoostingClassifier,\n",
        "    LogisticRegression,\n",
        "    SVC,\n",
        "    DecisionTreeClassifier,\n",
        "    KNeighborsClassifier,\n",
        "    MLPClassifier\n",
        "]\n",
        "\n",
        "hyperparameters = [\n",
        "    { \n",
        "        'max_depth': [3, 5, 7, 9],\n",
        "        'learning_rate': [0.1, 0.5, 1.0],\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'gamma': [0.0, 0.1, 0.5],\n",
        "        'subsample': [0.5, 0.8, 1.0],\n",
        "        'colsample_bytree': [0.5, 0.8, 1.0],\n",
        "        'tree_method': ['gpu_hist'],  # Use GPU for XGBoost\n",
        "        'gpu_id': [0]  # Set GPU ID to 0\n",
        "    },\n",
        "    {\n",
        "        'max_depth': [3, 5, 7],\n",
        "        'learning_rate': [0.1, 0.5, 1.0],\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'num_leaves': [31, 62, 127],\n",
        "        'subsample': [0.5, 0.8, 1.0],\n",
        "        'colsample_bytree': [0.5, 0.8, 1.0],\n",
        "        'reg_lambda': [0.0, 0.1, 0.5],\n",
        "        'device': ['gpu'],  # Use GPU for LightGBM\n",
        "        'gpu_device_id': [0],  # Set GPU ID to 0\n",
        "        'verbose': [-1],  # Disable text information\n",
        "        'silent': [True]  # Disable text information (alternative)\n",
        "    },\n",
        "    {\n",
        "        'depth': [3, 5, 7],\n",
        "        'learning_rate': [0.1, 0.5, 1.0],\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'l2_leaf_reg': [0.0, 0.1, 0.5],\n",
        "        'task_type': ['GPU'],  # Use GPU for CatBoost\n",
        "        'verbose': [False]  # Disable text information\n",
        "    },\n",
        "    {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [3, 5, 7],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 5, 10]\n",
        "    },\n",
        "    {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.1, 0.5, 1.0],\n",
        "        'max_depth': [3, 5, 7],\n",
        "        'subsample': [0.5, 0.8, 1.0]\n",
        "    },\n",
        "    {\n",
        "        'C': [0.1, 1.0, 10.0]\n",
        "    },\n",
        "    {\n",
        "        'kernel': ['rbf', 'linear'],\n",
        "        'C': [0.1, 1.0, 10.0],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    },\n",
        "    {\n",
        "        'max_depth': [3, 5, 7],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 5, 10]\n",
        "    },\n",
        "    {\n",
        "        'n_neighbors': [3, 5, 10],\n",
        "        'weights': ['uniform', 'distance']\n",
        "    },\n",
        "    {\n",
        "        'hidden_layer_sizes': [(50, 50), (100, 100), (200, 200)],\n",
        "        'activation': ['relu', 'tanh'],\n",
        "        'solver': ['adam', 'sgd'],\n",
        "        'alpha': [0.0001, 0.001, 0.01],\n",
        "        'learning_rate': ['constant', 'invscaling']\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p2hgHPOreqg",
        "outputId": "88b4442e-408d-4e41-deff-d690c40cbeb7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Encode categorical feature\n",
        "type_dict = {\"L\": 1, \"M\": 2, \"H\": 3}\n",
        "data['Type'] = data['Type'].map(type_dict)\n",
        "\n",
        "# Separate features and labels\n",
        "X = data.drop(['UDI', 'Product ID', 'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF'], axis=1)\n",
        "y = data[['TWF', 'HDF', 'PWF', 'OSF', 'RNF']]\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=77)\n",
        "\n",
        "repetition_class_ratio_before_da= y_train.sum(axis=0)/y_train.shape[0]\n",
        "print(\"before MLSMOTE \\n\", repetition_class_ratio_before_da)\n",
        "\n",
        "\n",
        "# Infer the categorical feature from the data columns\n",
        "categorical_features = [i for i, col in enumerate(X.columns) if col == 'Type']\n",
        "\n",
        "# Create an instance of MLSMOTE\n",
        "mlsmote = mlsmote.MLSMOTE(categorical_features=categorical_features,input_columns=X_train.columns, label_columns=y_train.columns,random_state=77)\n",
        "\n",
        "# Resample the data using MLSMOTE\n",
        "X_train_res, y_train_res = mlsmote.fit_resample(X_train, y_train)   \n",
        "\n",
        "# Convert X_train_res and y_train_res to DataFrames\n",
        "X_train = pd.DataFrame(X_train_res, columns=X_train.columns)\n",
        "y_train = pd.DataFrame(y_train_res, columns=y_train.columns)\n",
        "\n",
        "\n",
        "repetition_class_ratio_after_da= y_train.sum(axis=0)/y_train.shape[0]\n",
        "print(\"after MLSMOTE \\n\", repetition_class_ratio_after_da)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "# scaler = MinMaxScaler()\n",
        "\n",
        "# Scale the continuous features\n",
        "X_train_res_continuous = scaler.fit_transform(X_train.drop('Type', axis=1))\n",
        "X_test_continuous = scaler.transform(X_test.drop('Type', axis=1))\n",
        "\n",
        "# Concatenate the categorical feature with the scaled continuous features\n",
        "X_train = np.concatenate((X_train[['Type']], X_train_res_continuous), axis=1)\n",
        "X_test = np.concatenate((X_test[['Type']], X_test_continuous), axis=1)\n",
        "\n",
        "\n",
        "\n",
        "best_score = 0\n",
        "best_params = None\n",
        "best_classifier = None\n",
        "\n",
        "results = []\n",
        "for classifier, hyperparameter in zip(classifiers, hyperparameters):\n",
        "    hyperparameter_combinations = [dict(zip(hyperparameter.keys(), v)) for v in product(*hyperparameter.values())]\n",
        "    for hyperparameter_combination in tqdm(hyperparameter_combinations, desc=f\"Training {classifier.__name__}\"):\n",
        "        clf_params = hyperparameter_combination.copy()\n",
        "        if 'random_state' in signature(classifier).parameters:\n",
        "            clf_params['random_state'] = 77\n",
        "        clf = BinaryRelevance(classifier(**clf_params))\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred = clf.predict(X_test)\n",
        "        micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
        "        jaccard_sim = jaccard_score(y_test, y_pred, average='micro')\n",
        "        score = micro_f1 * jaccard_sim\n",
        "        results.append({\n",
        "            'classifier': classifier.__name__,\n",
        "            'hyperparameters': hyperparameter_combination,\n",
        "           'micro_f1': micro_f1,\n",
        "            'jaccard_sim': jaccard_sim,\n",
        "           'score': score\n",
        "        })\n",
        "\n",
        "with open('results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('results.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "scores_with_indices = [(i, item['score']) for i, item in enumerate(data)]\n",
        "top_10_scores_with_indices = sorted(scores_with_indices, key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "for i, score in top_10_scores_with_indices:\n",
        "    print(f\"Index: {i}, Score: {score}\")\n",
        "best_params=data[top_10_scores_with_indices[0][0]]['hyperparameters']\n",
        "best_classifier=data[top_10_scores_with_indices[0][0]]['classifier']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Best classifier: {best_classifier}\", f\", Best hyperparameters: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the best classifier\n",
        "best_classifier = eval(best_classifier)\n",
        "clf = BinaryRelevance(best_classifier(**best_params))\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "# Convert sparse matrix to dense NumPy array\n",
        "y_pred_dense = y_pred.toarray()\n",
        "\n",
        "# add non-failure column to the prediction\n",
        "y_pred_non_failure = ~np.any(y_pred_dense, axis=1)\n",
        "y_pred_dense = np.hstack((y_pred_dense, y_pred_non_failure.reshape(-1, 1)))\n",
        "y_pred_dense = np.array(y_pred_dense)\n",
        "\n",
        "# add non-failure column to the ground truth\n",
        "y_test_non_failure = ~np.any(y_test, axis=1)\n",
        "y_test = np.hstack((np.array(y_test), np.array(y_test_non_failure).reshape(-1, 1)))\n",
        "y_test_cr = np.array(y_test)\n",
        "\n",
        "# Calculate confusion matrix and classification report\n",
        "print(\"Confusion Matrix:\")\n",
        "for i, label_name in enumerate(['TWF', 'HDF', 'PWF', 'OSF', 'RNF', 'Non-failure']):\n",
        "    print(f\"{label_name}:\")\n",
        "    print(confusion_matrix(y_test_cr[:, i], y_pred_dense[:, i]))\n",
        "    print()\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_cr, y_pred_dense, target_names=['TWF', 'HDF', 'PWF', 'OSF', 'RNF', 'Non-failure']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification Report(10th best model):\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "         TWF       0.50      0.11      0.18         9\n",
        "         HDF       1.00      0.91      0.95        22\n",
        "         PWF       1.00      0.83      0.91        12\n",
        "         OSF       0.94      0.89      0.91        18\n",
        "         RNF       0.00      0.00      0.00         4\n",
        "         Non-failure       0.99      1.00      1.00      1940\n",
        "         micro avg       0.99      0.99      0.99      2005\n",
        "         macro avg       0.74      0.62      0.66      2005\n",
        "         weighted avg       0.99      0.99      0.99      2005\n",
        "         samples avg       0.99      0.99      0.99      2005"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification Report(Before MLSMOTE):\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "         TWF       0.00      0.00      0.00         9\n",
        "         HDF       1.00      0.95      0.98        22\n",
        "         PWF       0.75      1.00      0.86        12\n",
        "         OSF       1.00      0.94      0.97        18\n",
        "         RNF       0.00      0.00      0.00         4\n",
        "         Non-failure       0.99      1.00      1.00      1940\n",
        "         micro avg       0.99      0.99      0.99      2005\n",
        "         macro avg       0.62      0.65      0.63      2005\n",
        "         weighted avg       0.98      0.99      0.99      2005\n",
        "         samples avg       0.99      0.99      0.99      2005"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification Report(After MLSMOTE):\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "         TWF       0.33      0.11      0.17         9\n",
        "         HDF       1.00      0.95      0.98        22\n",
        "         PWF       0.80      1.00      0.89        12\n",
        "         OSF       0.94      0.83      0.88        18\n",
        "         RNF       0.00      0.00      0.00         4\n",
        "         Non-failure       0.99      1.00      1.00      1940\n",
        "         micro avg       0.99      0.99      0.99      2005\n",
        "         macro avg       0.68      0.65      0.65      2005\n",
        "         weighted avg       0.99      0.99      0.99      2005\n",
        "         samples avg       0.99      0.99      0.99      2005"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conf_mat = np.zeros((6, 6))\n",
        "\n",
        "for i in range(6):\n",
        "    for j in range(6):\n",
        "        conf_mat[i, j] = np.sum((y_test[:, i] == 1) & (y_pred_dense[:, j] == 1))\n",
        "\n",
        "label_names = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF', 'Non-failure']\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(conf_mat, annot=True,fmt=\".0f\", cmap='Blues',xticklabels=label_names, yticklabels=label_names)\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# find acc\n",
        "acc = np.sum(np.diag(conf_mat)) / np.sum(conf_mat)\n",
        "print(\"Accuracy: \", acc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
